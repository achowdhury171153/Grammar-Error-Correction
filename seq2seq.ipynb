{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled19.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP-M3ZPvqiy8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7e0034f2-fc07-4f05-bcc1-1285578c7729"
      },
      "source": [
        "# adapted from https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, TimeDistributed, RepeatVector, Dense\n",
        "import numpy as np\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "wandb.init()  #opened from my wandb account! :D\n",
        "config = wandb.config\n",
        "\n",
        "class CharacterTable(object):\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one hot integer representation\n",
        "    + Decode the one hot integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"Initialize character table.\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"One hot encode given string C.\n",
        "        # Arguments\n",
        "            num_rows: Number of rows in the returned one hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return ''.join(self.indices_char[x] for x in x)\n",
        "\n",
        "# Parameters for the model and dataset.\n",
        "config.training_size = 50000\n",
        "config.digits = 5\n",
        "config.hidden_size = 128\n",
        "config.batch_size = 128\n",
        "\n",
        "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
        "# int is DIGITS.\n",
        "maxlen = config.digits + 1 + config.digits\n",
        "\n",
        "# All the numbers, plus sign and space for padding.\n",
        "chars = '0123456789+- '\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print('Generating data...')\n",
        "while len(questions) < config.training_size:\n",
        "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
        "                    for i in range(np.random.randint(1, config.digits + 1))))\n",
        "    a, b = f(), f()\n",
        "    # Skip any addition questions we've already seen\n",
        "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    # Pad the data with spaces such that it is always MAXLEN.\n",
        "    q = '{}-{}'.format(a, b)\n",
        "    query = q + ' ' * (maxlen - len(q))\n",
        "    ans = str(a - b)\n",
        "    # Answers can be of maximum size DIGITS + 1.\n",
        "    ans += ' ' * (config.digits + 1 - len(ans))\n",
        "\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "    \n",
        "print('Total addition questions:', len(questions))\n",
        "\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(questions), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(questions), config.digits + 1, len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, maxlen)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, config.digits + 1)\n",
        "\n",
        "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
        "# digits.\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# Explicitly set apart 10% for validation data that we never train over.\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(config.hidden_size, input_shape=(maxlen, len(chars))))\n",
        "model.add(RepeatVector(config.digits + 1))\n",
        "model.add(LSTM(config.hidden_size, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(len(chars), activation='softmax')))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train the model each generation and show predictions against the validation\n",
        "# dataset.\n",
        "for iteration in range(1, 200):\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print('Iteration', iteration)\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=config.batch_size,\n",
        "              epochs=1,\n",
        "              validation_data=(x_val, y_val),callbacks=[WandbCallback()])\n",
        "    # Select 10 samples from the validation set at random so we can visualize\n",
        "    # errors.\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        preds = model.predict_classes(rowx, verbose=0)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        print('Q', q, end=' ')\n",
        "        print('T', correct, end=' ')\n",
        "        if correct == guess:\n",
        "            print('☑', end=' ')\n",
        "        else:\n",
        "            print('☒', end=' ')\n",
        "        print(guess)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Not authenticated.  Copy a key from https://app.wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "API Key: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/ashraf171153/uncategorized\" target=\"_blank\">https://app.wandb.ai/ashraf171153/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/ashraf171153/uncategorized/runs/3kmxz4ys\" target=\"_blank\">https://app.wandb.ai/ashraf171153/uncategorized/runs/3kmxz4ys</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Generating data...\n",
            "Total addition questions: 50000\n",
            "Vectorization...\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 128)               72704     \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 6, 128)            131584    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 6, 13)             1677      \n",
            "=================================================================\n",
            "Total params: 205,965\n",
            "Trainable params: 205,965\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 1\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 22s 496us/step - loss: 1.8122 - accuracy: 0.3603 - val_loss: 1.5989 - val_accuracy: 0.4160\n",
            "Q 99775-7     T 99768  ☒ 87779 \n",
            "Q 67513-2     T 67511  ☒ 55666 \n",
            "Q 2128-321    T 1807   ☒ 2111  \n",
            "Q 25-22873    T -22848 ☒ -22222\n",
            "Q 5-90172     T -90167 ☒ -29995\n",
            "Q 33739-15    T 33724  ☒ 35777 \n",
            "Q 29-15873    T -15844 ☒ -29997\n",
            "Q 498-0       T 498    ☒ 816   \n",
            "Q 19-2536     T -2517  ☒ -2226 \n",
            "Q 0-51        T -51    ☒ -1    \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 2\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 21s 478us/step - loss: 1.5497 - accuracy: 0.4292 - val_loss: 1.4947 - val_accuracy: 0.4463\n",
            "Q 7708-7021   T 687    ☒ -711  \n",
            "Q 11-293      T -282   ☒ -110  \n",
            "Q 3760-56690  T -52930 ☒ -56657\n",
            "Q 8-636       T -628   ☒ -777  \n",
            "Q 7383-2980   T 4403   ☒ -231  \n",
            "Q 573-9005    T -8432  ☒ -3333 \n",
            "Q 7297-129    T 7168   ☒ 7171  \n",
            "Q 450-66      T 384    ☒ 45    \n",
            "Q 9-6143      T -6134  ☒ -4007 \n",
            "Q 0-148       T -148   ☒ -101  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 3\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 21s 478us/step - loss: 1.4738 - accuracy: 0.4521 - val_loss: 1.4222 - val_accuracy: 0.4660\n",
            "Q 1-257       T -256   ☒ -666  \n",
            "Q 85-1726     T -1641  ☒ -6622 \n",
            "Q 2440-3543   T -1103  ☒ -219  \n",
            "Q 36-98257    T -98221 ☒ -88954\n",
            "Q 6713-73     T 6640   ☒ 7674  \n",
            "Q 6-40747     T -40741 ☒ -44444\n",
            "Q 876-9       T 867    ☒ 777   \n",
            "Q 30762-8577  T 22185  ☒ 2225  \n",
            "Q 831-495     T 336    ☒ -25   \n",
            "Q 9134-49     T 9085   ☒ 9992  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 4\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 22s 480us/step - loss: 1.4014 - accuracy: 0.4710 - val_loss: 1.3531 - val_accuracy: 0.4871\n",
            "Q 682-62      T 620    ☒ 622   \n",
            "Q 18-25       T -7     ☒ -1    \n",
            "Q 4-2965      T -2961  ☒ -4445 \n",
            "Q 0-1839      T -1839  ☒ -1018 \n",
            "Q 20-75       T -55    ☒ -11   \n",
            "Q 28-478      T -450   ☒ -446  \n",
            "Q 3505-9002   T -5497  ☒ -1056 \n",
            "Q 2-5286      T -5284  ☒ -8226 \n",
            "Q 3491-1523   T 1968   ☒ 311   \n",
            "Q 559-288     T 271    ☒ 224   \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 5\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 22s 479us/step - loss: 1.3324 - accuracy: 0.4961 - val_loss: 1.2783 - val_accuracy: 0.5121\n",
            "Q 6-948       T -942   ☒ -844  \n",
            "Q 8364-5556   T 2808   ☒ 5111  \n",
            "Q 4469-13     T 4456   ☒ 4431  \n",
            "Q 1-3000      T -2999  ☒ -3000 \n",
            "Q 14793-9     T 14784  ☒ 14171 \n",
            "Q 1-2342      T -2341  ☒ -2222 \n",
            "Q 17084-4     T 17080  ☒ 11771 \n",
            "Q 7987-18     T 7969   ☒ 7711  \n",
            "Q 2644-8219   T -5575  ☒ -2172 \n",
            "Q 120-0       T 120    ☒ 101   \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 6\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            " 3328/45000 [=>............................] - ETA: 20s - loss: 1.2821 - accuracy: 0.5164"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}